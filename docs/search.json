[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nWei Zhou\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data.\n\n\n\nI analyzed some data."
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "This is Project 1",
    "section": "",
    "text": "I cleaned some data."
  },
  {
    "objectID": "blog/project1/index.html#section-2-analysis",
    "href": "blog/project1/index.html#section-2-analysis",
    "title": "This is Project 1",
    "section": "",
    "text": "I analyzed some data."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog/HW1/index.html",
    "href": "blog/HW1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment aimed to evaluate how different fundraising strategies influence donor behavior. The standard letter served as a baseline, while the matching grant letter offered to match donations at a specific ratio, and the challenge grant letter set a fundraising goal that needed to be met for the funds to be unlocked. These treatments were designed to test the psychological and economic factors that motivate charitable giving, such as reciprocity, social pressure, and perceived impact.\nThe study measured key outcomes, including the likelihood of donating and the amount donated, to assess the effectiveness of each treatment. By randomly assigning participants to treatment groups, the researchers ensured that any observed differences in outcomes could be attributed to the fundraising strategy rather than external factors. This rigorous design allowed them to draw causal inferences about the impact of the treatments on donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/HW1/index.html#introduction",
    "href": "blog/HW1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment aimed to evaluate how different fundraising strategies influence donor behavior. The standard letter served as a baseline, while the matching grant letter offered to match donations at a specific ratio, and the challenge grant letter set a fundraising goal that needed to be met for the funds to be unlocked. These treatments were designed to test the psychological and economic factors that motivate charitable giving, such as reciprocity, social pressure, and perceived impact.\nThe study measured key outcomes, including the likelihood of donating and the amount donated, to assess the effectiveness of each treatment. By randomly assigning participants to treatment groups, the researchers ensured that any observed differences in outcomes could be attributed to the fundraising strategy rather than external factors. This rigorous design allowed them to draw causal inferences about the impact of the treatments on donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/HW1/index.html#data",
    "href": "blog/HW1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Display basic information about the dataset\nprint(\"Dataset Overview:\")\nprint(df.info())\n\n# Summary statistics\nprint(\"\\nSummary Statistics:\")\nprint(df.describe())\n\nDataset Overview:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n\nSummary Statistics:\n          treatment       control        ratio2        ratio3        size25  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.666813      0.333187      0.222311      0.222211      0.166723   \nstd        0.471357      0.471357      0.415803      0.415736      0.372732   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n75%        1.000000      1.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n             size50       size100        sizeno         askd1         askd2  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.166623      0.166723      0.166743      0.222311      0.222291   \nstd        0.372643      0.372732      0.372750      0.415803      0.415790   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n       ...        redcty       bluecty        pwhite        pblack  \\\ncount  ...  49978.000000  49978.000000  48217.000000  48047.000000   \nmean   ...      0.510245      0.488715      0.819599      0.086710   \nstd    ...      0.499900      0.499878      0.168561      0.135868   \nmin    ...      0.000000      0.000000      0.009418      0.000000   \n25%    ...      0.000000      0.000000      0.755845      0.014729   \n50%    ...      1.000000      0.000000      0.872797      0.036554   \n75%    ...      1.000000      1.000000      0.938827      0.090882   \nmax    ...      1.000000      1.000000      1.000000      0.989622   \n\n          page18_39     ave_hh_sz  median_hhincome        powner  \\\ncount  48217.000000  48221.000000     48209.000000  48214.000000   \nmean       0.321694      2.429012     54815.700533      0.669418   \nstd        0.103039      0.378115     22027.316665      0.193405   \nmin        0.000000      0.000000      5000.000000      0.000000   \n25%        0.258311      2.210000     39181.000000      0.560222   \n50%        0.305534      2.440000     50673.000000      0.712296   \n75%        0.369132      2.660000     66005.000000      0.816798   \nmax        0.997544      5.270000    200001.000000      1.000000   \n\n       psch_atlstba  pop_propurban  \ncount  48215.000000   48217.000000  \nmean       0.391661       0.871968  \nstd        0.186599       0.258654  \nmin        0.000000       0.000000  \n25%        0.235647       0.884929  \n50%        0.373744       1.000000  \n75%        0.530036       1.000000  \nmax        1.000000       1.000000  \n\n[8 rows x 48 columns]\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.api as sm\n\nvariables_to_test = ['mrm2', 'freq', 'years']\n\nfor var in variables_to_test:\n    print(f\"\\n=== Testing variable: {var} ===\")\n    group_means = df.groupby('treatment')[var].mean()\n    group_counts = df.groupby('treatment')[var].count()\n    group_vars = df.groupby('treatment')[var].var()\n    n1 = group_counts[1]  \n    n0 = group_counts[0] \n    mean1 = group_means[1]\n    mean0 = group_means[0]\n    var1 = group_vars[1]\n    var0 = group_vars[0]\n    \n    print(f\"Treatment mean: {mean1:.3f}, Control mean:{mean0:.3f}\")\n    print(f\"Treatment std: {var1**0.5:.3f}, Control variance:{var0**0.5:.3f}\")\n\n    se = np.sqrt(var1/n1 + var0/n0)\n    t_stat = (mean1 - mean0) / se\n    dfree = (var1/n1 + var0/n0)**2 / ((var1**2)/((n1**2)*(n1-1)) + (var0**2)/((n0**2)*(n0-1)))\n    p_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), df=dfree))\n    print(f\"T-test: t = {t_stat:.3f}, p = {p_value:.3f}\")\n\n    X = sm.add_constant(df['treatment'])\n    y = df[var]\n    model = sm.OLS(y, X, missing='drop').fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n    print(f\"Regression: coef = {coef:.3f}, p = {pval:.3f}\")\n\n\n=== Testing variable: mrm2 ===\nTreatment mean: 13.012, Control mean:12.998\nTreatment std: 12.086, Control variance:12.074\nT-test: t = 0.120, p = 0.905\nRegression: coef = 0.014, p = 0.905\n\n=== Testing variable: freq ===\nTreatment mean: 8.035, Control mean:8.047\nTreatment std: 11.390, Control variance:11.404\nT-test: t = -0.111, p = 0.912\nRegression: coef = -0.012, p = 0.912\n\n=== Testing variable: years ===\nTreatment mean: 6.078, Control mean:6.136\nTreatment std: 5.442, Control variance:5.625\nT-test: t = -1.091, p = 0.275\nRegression: coef = -0.058, p = 0.270\n\n\nThe t-test and linear regression both test for mean differences between the treatment and control groups on these baseline variables, and the results should be identical. This result is also aligned with the Table 1 in the paper. ## Experimental Results\n\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates by group\ndonation_rates = df.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\n\nplt.bar(labels, donation_rates)\nplt.ylabel('Proportion Donated')\nplt.title('Proportion of People Who Donated by Group')\nplt.ylim(0, donation_rates.max() * 1.2)\nplt.show()\n\n\n\n\n\n\n\n\nAbove is the proportion of people who donated in control and treatment groups.\nNext, I run a t-test and a bivariate linear regression between the treatment and control groups on the binary outcome of whether any charitable donation was made.\n\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy import stats\n\ndf_clean = df[['gave', 'treatment']].dropna()\n\ngave_treatment = df_clean[df_clean['treatment'] == 1]['gave']\ngave_control = df_clean[df_clean['treatment'] == 0]['gave']\n\nt_stat, p_value = stats.ttest_ind(\n    gave_treatment,\n    gave_control,\n    equal_var=False\n)\nprint(f\"T-test (scipy): t = {t_stat:.3f}, p = {p_value:.4f}\")\n\n# Linear regression\nX = sm.add_constant(df_clean['treatment'])\ny = df_clean['gave']\nmodel = sm.OLS(y, X).fit()\ncoef = model.params['treatment']\npval = model.pvalues['treatment']\nprint(f\"Regression: coef = {coef:.3f}, p = {pval:.4f}\")\n\nT-test (scipy): t = 3.209, p = 0.0013\nRegression: coef = 0.004, p = 0.0019\n\n\nBoth the t-test and regression show whether the treatment group is more likely to donate than the control group.\nThe p-value is small(&lt;0.01), which means the difference is statistically significant: the matching grant treatment increases the likelihood of giving. This suggests that people are more likely to donate when their gift is matched, supporting the idea that matching grants motivate charitable behavior.\nThen, I ran a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control.\n\ndf_clean = df[['gave', 'treatment']].dropna()\n\nX = sm.add_constant(df_clean['treatment'])\ny = df_clean['gave']\n\nprobit_model = sm.Probit(y, X).fit()\n\nmarginal_effects = probit_model.get_margeff(at='overall')\nprint(marginal_effects.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nThe coefficient on ‘treatment’ should match Table 3 column 1 in the paper. A positive and significant coefficient here means being assigned to the treatment group increases the probability of making a donation, consistent with the main findings.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nFirst, I used a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not between every two sizes (1:1 vs 2:1, 2:1 vs 3:1, 1:1 vs 3:1).\n\ndf_ratio = df[(df['treatment'] == 1) & (df['ratio'].notnull()) & (df['gave'].notnull())]\n\n# 1:1 vs 2:1\ngave_1to1 = df_ratio[df_ratio['ratio'] == 1]['gave']\ngave_2to1 = df_ratio[df_ratio['ratio'] == 2]['gave']\nt_stat_12, p_val_12 = stats.ttest_ind(gave_1to1, gave_2to1, equal_var=False)\nprint(f\"1:1 vs 2:1 match: t = {t_stat_12:.3f}, p = {p_val_12:.4f}\")\n\n# 2:1 vs 3:1\ngave_3to1 = df_ratio[df_ratio['ratio'] == 3]['gave']\nt_stat_23, p_val_23 = stats.ttest_ind(gave_2to1, gave_3to1, equal_var=False)\nprint(f\"2:1 vs 3:1 match: t = {t_stat_23:.3f}, p = {p_val_23:.4f}\")\n\n# 1:1 vs 3:1\nt_stat_13, p_val_13 = stats.ttest_ind(gave_1to1, gave_3to1, equal_var=False)\nprint(f\"1:1 vs 3:1 match: t = {t_stat_13:.3f}, p = {p_val_13:.4f}\")\n\n1:1 vs 2:1 match: t = -0.965, p = 0.3345\n2:1 vs 3:1 match: t = -0.050, p = 0.9600\n1:1 vs 3:1 match: t = -1.015, p = 0.3101\n\n\nThese t-tests shows that there is no statistically significant difference in donation rates between the match ratios.\nThis supports the authors’ comment that “neither the match thresh- old nor the example amount had a meaningful influence on behavior.”\nNext, I assessed the same issue using a regression. I created the variable ratio2, and ratio3, and then regressed gave on them.\n\ndf_ratio = df[(df['treatment'] == 1) & (df['ratio'].isin([1,2,3])) & (df['gave'].notnull())]\n\ndf_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\nX = sm.add_constant(df_ratio[['ratio2', 'ratio3']])\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.524\nTime:                        16:27:28   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n/var/folders/4l/zkt81q5j4xlbn6fjv2v8jj880000gn/T/ipykernel_61261/1592154894.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\n/var/folders/4l/zkt81q5j4xlbn6fjv2v8jj880000gn/T/ipykernel_61261/1592154894.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\n\n\nThe coefficients on the dummy variables for match ratios show the difference in donation probability compared to the 1:1 match (the omitted group). The coefficients are small and not statistically significant, which means increasing the match ratio does not meaningfully affect the likelihood of donating.\nThis matches the earlier t-test results and supports the paper’s finding.\nI also calculated the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios in two ways – directly from the data, and by computing the differences in the fitted coefficients of the previous regression.\n\ngave_1to1 = df_ratio[df_ratio['ratio'] == 1]['gave']\ngave_2to1 = df_ratio[df_ratio['ratio'] == 2]['gave']\ngave_3to1 = df_ratio[df_ratio['ratio'] == 3]['gave']\n\ndiff_12 = gave_2to1.mean() - gave_1to1.mean()\ndiff_13 = gave_3to1.mean() - gave_1to1.mean()\ndiff_23 = gave_3to1.mean() - gave_2to1.mean()\nprint(f\"Direct from data: Response rate difference (2:1 - 1:1): {diff_12:.4f}\")\nprint(f\"Direct from data: Response rate difference (3:1 - 1:1): {diff_13:.4f}\")\nprint(f\"Direct from data: Response rate difference (3:1 - 2:1): {diff_23:.4f}\")\n\n\ncoef_2 = model.params['ratio2']\ncoef_3 = model.params['ratio3']\nprint(f\"From regression: Response rate difference (2:1 - 1:1): {coef_2:.4f}\")\nprint(f\"From regression: Response rate difference (3:1 - 1:1): {coef_3:.4f}\")\nprint(f\"From regression: Response rate difference (3:1 - 2:1): {(coef_3 - coef_2):.4f}\")\n\nDirect from data: Response rate difference (2:1 - 1:1): 0.0019\nDirect from data: Response rate difference (3:1 - 1:1): 0.0020\nDirect from data: Response rate difference (3:1 - 2:1): 0.0001\nFrom regression: Response rate difference (2:1 - 1:1): 0.0019\nFrom regression: Response rate difference (3:1 - 1:1): 0.0020\nFrom regression: Response rate difference (3:1 - 2:1): 0.0001\n\n\nBoth the direct calculation and regression coefficients show that the differences in response rates between 1:1, 2:1, and 3:1 match ratios are very small and not statistically significant. This suggests that increasing the match ratio does not meaningfully increase the likelihood of donating, confirming the findings in the paper.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nI first examined whether the treatment group gives a different average donation amount than the control group by t-test.\n\ndf_amt = df[['amount', 'treatment']].dropna()\n\namount_treat = df_amt[df_amt['treatment'] == 1]['amount']\namount_ctrl = df_amt[df_amt['treatment'] == 0]['amount']\nt_stat, p_value = stats.ttest_ind(amount_treat, amount_ctrl, equal_var=False)\nprint(f\"T-test: t = {t_stat:.3f}, p = {p_value:.4f}\")\n\nT-test: t = 1.918, p = 0.0551\n\n\nThe p-value is large (&gt;0.05), it means there is no statistically significant difference in average donation amount between groups. This suggests that while matching grants may increase the likelihood of giving, they do not necessarily increase the average amount donated.\nThen, I limited the data to just people who made a donation and repeat the previous analysis. This regression allows me to analyze how much respondents donate conditional on donating some positive amount.\n\ndf_positive = df[(df['gave'] == 1) & (df['treatment'].notnull())].copy()\n\nX = sm.add_constant(df_positive['treatment'])\ny = df_positive['amount']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        16:27:28   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThis analysis examines whether, among those who donated, the average donation amount differs between treatment and control groups.\nThe treatment coefficient is not statistically significant, which suggests that matching grants do not increase the average donation size among donors—only the likelihood of giving. Because treatment was randomly assigned, the coefficient can be interpreted causally: it estimates the effect of being offered a match on the average donation amount, conditional on donating.\nHere I make two plots to show the distribution of the donation amounts for people who donated in treatment and control groups. This also support the conclusion that matching grants do not increase the average donation size among donors—only the likelihood of giving.\n\ndf_positive = df[(df['amount'] &gt; 0) & (df['treatment'].notnull())]\n\namount_treat = df_positive[df_positive['treatment'] == 1]['amount']\nmean_treat = amount_treat.mean()\n\namount_ctrl = df_positive[df_positive['treatment'] == 0]['amount']\nmean_ctrl = amount_ctrl.mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control histogram\naxes[0].hist(amount_ctrl, bins=30, color='gray', alpha=0.7)\naxes[0].axvline(mean_ctrl, color='red', linestyle='dashed', linewidth=2, label=f'Mean = {mean_ctrl:.2f}')\naxes[0].set_title('Control Group')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Number of Donors')\naxes[0].legend()\n\n# Treatment histogram\naxes[1].hist(amount_treat, bins=30, color='skyblue', alpha=0.7)\naxes[1].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2, label=f'Mean = {mean_treat:.2f}')\naxes[1].set_title('Treatment Group')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/HW1/index.html#simulation-experiment",
    "href": "blog/HW1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nTo illustrate Law of Large Numbers, I simulated 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. I then calculated a vector of 10,000 differences, and then plot the cumulative average of that vector of differences.\n\nnp.random.seed(42)\n\n\ncontrol_draws = np.random.binomial(1, 0.018, 10000)\ntreatment_draws = np.random.binomial(1, 0.022, 10000)\n\n# Calculate vector of differences\ndiffs = treatment_draws - control_draws\n\n# Cumulative average of differences\ncum_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# True difference in means\ntrue_diff = 0.022 - 0.018\n\nplt.figure(figsize=(10, 5))\nplt.plot(cum_avg, label='Cumulative Average of Differences')\nplt.axhline(true_diff, color='red', linestyle='--', label='True Difference in Means')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Cumulative Average of Simulated Differences (Treatment - Control)')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis plot shows how the cumulative average of the simulated differences between treatment and control groups converges to the true difference in means as the number of simulations increases.\nAs more samples are drawn, the cumulative average stabilizes around the true value (0.004), illustrating the Law of Large Numbers.\n\n\nCentral Limit Theorem\nTo illustrate Central Limit Theorem, I made 4 histograms at sample sizes 50, 200, 500, and 1000. For each sample size, e.g. 50, I took 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that I had 1000 averages.\n\nnp.random.seed(42)\n\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_reps = 1000\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    avg_diffs = []\n    for _ in range(n_reps):\n        control_draws = np.random.binomial(1, p_control, n)\n        treatment_draws = np.random.binomial(1, p_treatment, n)\n        avg_diff = treatment_draws.mean() - control_draws.mean()\n        avg_diffs.append(avg_diff)\n    axes[i].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n    axes[i].axvline(0, color='red', linestyle='dashed', linewidth=2, label='Zero')\n    axes[i].axvline(p_treatment - p_control, color='green', linestyle='dashed', linewidth=2, label='True Diff')\n    axes[i].set_title(f'Sample Size = {n}')\n    axes[i].set_xlabel('Average Difference')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nEach histogram shows the distribution of average differences in donation rates between treatment and control groups, simulated 1000 times for different sample sizes.\nAs the sample size increases, the distribution becomes narrower and more centered around the true difference (green line), and zero (red line) moves further into the tail.\nThis illustrates the Central Limit Theorem: with larger samples, our estimate of the difference becomes more precise and less likely to include zero if there is a true effect."
  }
]