[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "Poisson Regression Examples\n\n\n\n\n\n\nYour Name\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nWei Zhou\n\n\nMay 7, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/HW2/index.html",
    "href": "blog/HW2/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nWe first read in the data and draw histograms for number of patents by customer status. We observed the distribution is more right skewed, and customer of Blueprinty seem to have more patents than non-customers in average.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"blueprinty.csv\")\n\ncolors = {0: 'skyblue', 1: 'salmon'}\n\nplt.figure(figsize=(8, 5))\nfor status in df['iscustomer'].unique():\n    subset = df[df['iscustomer'] == status]\n    plt.hist(subset['patents'], bins=30, alpha=0.7, \n             label=f'Customer={status}', color=colors[status], edgecolor='black')\n\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.title('Distribution of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\nmean_patents = df.groupby('iscustomer')['patents'].mean()\n\nprint(f\"Mean number of patents by customer status:{mean_patents}\")\n\n\n\n\n\n\n\n\nMean number of patents by customer status:iscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nThus, we also look into the region and age distribution by customer status.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nregion_counts = df.groupby(['region', 'iscustomer']).size().unstack(fill_value=0)\nprint(region_counts)\n\nregion_counts.plot(kind='bar', figsize=(8, 5), color=['skyblue', 'salmon'])\nplt.title('Region Distribution by Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Count')\nplt.legend(title='Customer Status')\nplt.xticks(rotation=45)\nplt.grid(axis='y')\nplt.tight_layout()\nplt.show()\n\nage_stats = df.groupby('iscustomer')['age'].agg(['mean', 'var'])\nprint(\"Age mean and variance by customer status:\")\nprint(age_stats)\n\nplt.figure(figsize=(8, 5))\nfor status, color in zip([0, 1], ['skyblue', 'salmon']):\n    subset = df[df['iscustomer'] == status]\n    sns.histplot(subset['age'], kde=True, color=color, label=f'Customer={status}', stat='density', alpha=0.6)\n\nplt.title('Age Distribution by Customer Status')\nplt.xlabel('Age')\nplt.ylabel('Density')\nplt.legend()\nplt.grid(True)\nplt.show()\n\niscustomer    0    1\nregion              \nMidwest     187   37\nNortheast   273  328\nNorthwest   158   29\nSouth       156   35\nSouthwest   245   52\n\n\n\n\n\n\n\n\n\nAge mean and variance by customer status:\n                 mean        var\niscustomer                      \n0           26.101570  48.238937\n1           26.900208  61.069187\n\n\n\n\n\n\n\n\n\nFor the age distribution, we found that customers tend to be slightly older than non-customers. The age distributions are similar overall, but non-customer is more like normal distribution with age 25 having the largest density, while the customer’s density is flat within the range 20-30. Thus, customer shows higher variability in age.\nRegionally, the Northeast stands out with the highest number of customer firms (328), while other regions such as the Southwest, Midwest, South, and Northwest have significantly fewer customers. This suggests that both firm age and geographic location may be associated with customer status, with the Northeast possibly representing a key market area.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nHere the likelihood function for Poisson distribution and the python code to caculate it.\n\\[\nP(Y_i = y_i) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!}\n\\]\n\nimport numpy as np\nfrom scipy.special import gammaln  # For log(y!)\n\n\ndef poisson_loglikelihood(lmbda, Y):\n    Y = np.asarray(Y)\n    return np.sum(-lmbda + Y * np.log(lmbda) - gammaln(Y + 1))\n\nNext, we use the function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas.\n\nY = df['patents']\n\n# Define a range of lambda values\nlambda_range = np.linspace(0.1, 10, 200)  # Avoid lambda=0 due to log(0)\n\n# Compute log-likelihoods for each lambda\nlog_likelihoods = [poisson_loglikelihood(lmbda, Y) for lmbda in lambda_range]\n\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_range, log_likelihoods, color='blue')\nplt.title('Poisson Log-Likelihood vs Lambda')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThis plot shows the log likelihood function of a Poisson model for a range of lambda, using the observed number of patents as the input data. The curve peaks at the value of 3 that best fits the data, which is the maximum likelihood estimate (MLE).\nWe can also look at it in mathematical view:\nThe log-likelihood function for \\(Y = \\{y_1, y_2, \\dots, y_n\\}\\) is:\n\\[\n\\log L(\\lambda; Y) = \\sum_{i=1}^n \\left( -\\lambda + y_i \\log \\lambda - \\log(y_i!) \\right)\n\\]\nTaking the derivative with respect to \\(\\lambda\\):\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda; Y) = \\sum_{i=1}^n \\left( -1 + \\frac{y_i}{\\lambda} \\right)\n= -n + \\frac{1}{\\lambda} \\sum_{i=1}^n y_i\n\\]\nSet the derivative equal to zero:\n\\[\n-n + \\frac{1}{\\lambda} \\sum_{i=1}^n y_i = 0\n\\]\nSolving for \\(\\lambda\\):\n\\[\n\\lambda_{\\text{MLE}} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\bar{Y}\n\\]\nThis result feels right, because the mean of a Poisson distribution is \\(\\lambda\\), and we’re estimating it using the sample mean.\nNow we find the MLE by optimizing my likelihood function.\n\nfrom scipy.optimize import minimize_scalar\n\n# Objective function: negative log-likelihood (for minimization)\ndef neg_loglikelihood(lmbda):\n    return -poisson_loglikelihood(lmbda, Y)\n\n# Use bounded scalar optimization\nresult = minimize_scalar(neg_loglikelihood, bounds=(0.01, 10), method='bounded')\n\nlambda_mle = result.x\nprint(f\"MLE of lambda: {lambda_mle:.4f}\")\n\nMLE of lambda: 3.6847\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nNow we create a new log-likelihood function for Poisson model with an additional argument to take in a covariate matrix X. We will use it to find the MLE vector and the Hessian of the Poisson model with covariates. Then we will use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\nfrom scipy.special import gammaln\nfrom scipy.optimize import minimize\nimport math\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.asarray(beta).ravel()\n    X = np.asarray(X)\n    Y = np.asarray(Y)\n\n    linpred = X.dot(beta)\n    linpred = np.clip(linpred, -100, 100)\n\n    mu = np.array([math.exp(val) for val in linpred])\n\n    if np.any(mu &lt;= 0) or np.any(np.isnan(mu)):\n        return -np.inf\n\n    return np.sum(Y * np.log(mu) - mu - gammaln(Y + 1))\n\n\ndf['age_squared'] = df['age'] ** 2\nregion_dummies = pd.get_dummies(df['region'], drop_first=True)\nX = pd.concat([\n    pd.Series(1, index=df.index, name='intercept'),\n    df[['age', 'age_squared', 'iscustomer']],\n    region_dummies\n], axis=1)\nY = df['patents'].values\nX_matrix = X.values\n\ndef neg_loglikelihood(beta, Y, X):\n    return -poisson_regression_loglikelihood(beta, Y, X)\n\n# Optimize to find MLE\ninitial_beta = np.zeros(X_matrix.shape[1])\nresult = minimize(neg_loglikelihood, x0=initial_beta, args=(Y, X_matrix), method='BFGS')\n\n# Extract MLE and Hessian inverse\nbeta_mle = result.x\nhess_inv = result.hess_inv\n# Ensure Hessian inverse is array\nif not isinstance(hess_inv, np.ndarray):\n    hess_inv = hess_inv.todense()\nhess_inv = np.asarray(hess_inv)\n\n# Compute standard errors\nstd_errors = np.sqrt(np.diag(hess_inv))\n\n# Build results table\nresults_df = pd.DataFrame({\n    \"Coefficient\": beta_mle,\n    \"Std. Error\": std_errors\n}, index=X.columns)\nresults_df\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.509992\n0.000099\n\n\nage\n0.148706\n0.003625\n\n\nage_squared\n-0.002972\n0.000095\n\n\niscustomer\n0.207609\n0.028353\n\n\nNortheast\n0.029155\n0.042425\n\n\nNorthwest\n-0.017578\n0.053198\n\n\nSouth\n0.056565\n0.051524\n\n\nSouthwest\n0.050567\n0.046869\n\n\n\n\n\n\n\nNow we check our results using Python sm.GLM() function.\n\nimport statsmodels.api as sm\n\nX_numeric = X.astype(float)\nY_numeric = Y.astype(float)\n\npoisson_model = sm.GLM(Y_numeric, X_numeric, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\nprint(poisson_results.summary())\n\n# And to extract coeffs and SEs:\nimport pandas as pd\nresult_table = pd.DataFrame({\n    'coef': poisson_results.params,\n    'std_err': poisson_results.bse\n})\nprint(result_table)\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        23:17:34   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n-------------------------------------------------------------------------------\nintercept      -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nage             0.1486      0.014     10.716      0.000       0.121       0.176\nage_squared    -0.0030      0.000    -11.513      0.000      -0.003      -0.002\niscustomer      0.2076      0.031      6.719      0.000       0.147       0.268\nNortheast       0.0292      0.044      0.669      0.504      -0.056       0.115\nNorthwest      -0.0176      0.054     -0.327      0.744      -0.123       0.088\nSouth           0.0566      0.053      1.074      0.283      -0.047       0.160\nSouthwest       0.0506      0.047      1.072      0.284      -0.042       0.143\n===============================================================================\n                 coef   std_err\nintercept   -0.508920  0.183179\nage          0.148619  0.013869\nage_squared -0.002970  0.000258\niscustomer   0.207591  0.030895\nNortheast    0.029170  0.043625\nNorthwest   -0.017575  0.053781\nSouth        0.056561  0.052662\nSouthwest    0.050576  0.047198\n\n\nFrom the result above, we can see age has a strong nonlinear relationship with patent counts: the negative age squared term and the positive age term shows that age increases the expected log count until 25, and then make it decline afterwards. Blueprinty customers produce about 23 percent more patents than non-customers (exp(0.208)≈1.23, p &lt; .001), given all other conditions equal. Once age and customer status are accounted for, none of the regions—Northeast, Northwest, South, or Southwest—differs significantly from the Midwest baseline.\nNow we want to conclude on the effect of Blueprinty’s software on patent success. Because the beta coefficients are not directly interpretable, we create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, we use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences._\n\ndef build_design_matrix(df, iscustomer=None, region_dummies=None):\n    X = pd.DataFrame({\n        'intercept': 1.0,\n        'age': df['age'].astype(float),\n        'age_squared': df['age_squared'].astype(float),\n    }, index=df.index)\n    \n    if region_dummies is not None:\n        region_dummies = region_dummies.astype(float)\n        X = pd.concat([X, region_dummies], axis=1)\n\n    if iscustomer is None:\n        X['iscustomer'] = df['iscustomer'].astype(float)\n    else:\n        X['iscustomer'] = float(iscustomer)\n        \n    cols_order = ['intercept', 'age', 'age_squared', 'iscustomer'] + list(region_dummies.columns)\n    return X[cols_order]\n\nX_full = build_design_matrix(df, region_dummies=region_dummies)\nX_0 = build_design_matrix(df, iscustomer=0, region_dummies=region_dummies)\nX_1 = build_design_matrix(df, iscustomer=1, region_dummies=region_dummies)\n\nY = df['patents'].astype(float)\n\npoisson_model = sm.GLM(Y, X_full, family=sm.families.Poisson())\npoisson_result = poisson_model.fit()\n\ny_pred_0 = poisson_result.predict(X_0)\ny_pred_1 = poisson_result.predict(X_1)\n\naverage_effect = np.mean(y_pred_1 - y_pred_0)\naverage_effect\n\n0.7927680710452626\n\n\nWe can see that, on average, Blueprinty customers are expected to produce approximately 0.79 more patents than if they were not customers, holding all other variables constant."
  },
  {
    "objectID": "blog/HW2/index.html#blueprinty-case-study",
    "href": "blog/HW2/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data.\ntodo: Compare histograms and means of number of patents by customer status. What do you observe?\nWe first read in the data and draw histograms for number of patents by customer status. We observed the distribution is more right skewed, and customer of Blueprinty seem to have more patents than non-customers in average.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv(\"blueprinty.csv\")\n\ncolors = {0: 'skyblue', 1: 'salmon'}\n\nplt.figure(figsize=(8, 5))\nfor status in df['iscustomer'].unique():\n    subset = df[df['iscustomer'] == status]\n    plt.hist(subset['patents'], bins=30, alpha=0.7, \n             label=f'Customer={status}', color=colors[status], edgecolor='black')\n\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\nplt.title('Distribution of Patents by Customer Status')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\nmean_patents = df.groupby('iscustomer')['patents'].mean()\n\nprint(f\"Mean number of patents by customer status:{mean_patents}\")\n\n\n\n\n\n\n\n\nMean number of patents by customer status:iscustomer\n0    3.473013\n1    4.133056\nName: patents, dtype: float64\n\n\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\nThus, we also look into the region and age distribution by customer status.\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nregion_counts = df.groupby(['region', 'iscustomer']).size().unstack(fill_value=0)\nprint(region_counts)\n\nregion_counts.plot(kind='bar', figsize=(8, 5), color=['skyblue', 'salmon'])\nplt.title('Region Distribution by Customer Status')\nplt.xlabel('Region')\nplt.ylabel('Count')\nplt.legend(title='Customer Status')\nplt.xticks(rotation=45)\nplt.grid(axis='y')\nplt.tight_layout()\nplt.show()\n\nage_stats = df.groupby('iscustomer')['age'].agg(['mean', 'var'])\nprint(\"Age mean and variance by customer status:\")\nprint(age_stats)\n\nplt.figure(figsize=(8, 5))\nfor status, color in zip([0, 1], ['skyblue', 'salmon']):\n    subset = df[df['iscustomer'] == status]\n    sns.histplot(subset['age'], kde=True, color=color, label=f'Customer={status}', stat='density', alpha=0.6)\n\nplt.title('Age Distribution by Customer Status')\nplt.xlabel('Age')\nplt.ylabel('Density')\nplt.legend()\nplt.grid(True)\nplt.show()\n\niscustomer    0    1\nregion              \nMidwest     187   37\nNortheast   273  328\nNorthwest   158   29\nSouth       156   35\nSouthwest   245   52\n\n\n\n\n\n\n\n\n\nAge mean and variance by customer status:\n                 mean        var\niscustomer                      \n0           26.101570  48.238937\n1           26.900208  61.069187\n\n\n\n\n\n\n\n\n\nFor the age distribution, we found that customers tend to be slightly older than non-customers. The age distributions are similar overall, but non-customer is more like normal distribution with age 25 having the largest density, while the customer’s density is flat within the range 20-30. Thus, customer shows higher variability in age.\nRegionally, the Northeast stands out with the highest number of customer firms (328), while other regions such as the Southwest, Midwest, South, and Northwest have significantly fewer customers. This suggests that both firm age and geographic location may be associated with customer status, with the Northeast possibly representing a key market area.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nHere the likelihood function for Poisson distribution and the python code to caculate it.\n\\[\nP(Y_i = y_i) = \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!}\n\\]\n\nimport numpy as np\nfrom scipy.special import gammaln  # For log(y!)\n\n\ndef poisson_loglikelihood(lmbda, Y):\n    Y = np.asarray(Y)\n    return np.sum(-lmbda + Y * np.log(lmbda) - gammaln(Y + 1))\n\nNext, we use the function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas.\n\nY = df['patents']\n\n# Define a range of lambda values\nlambda_range = np.linspace(0.1, 10, 200)  # Avoid lambda=0 due to log(0)\n\n# Compute log-likelihoods for each lambda\nlog_likelihoods = [poisson_loglikelihood(lmbda, Y) for lmbda in lambda_range]\n\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_range, log_likelihoods, color='blue')\nplt.title('Poisson Log-Likelihood vs Lambda')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThis plot shows the log likelihood function of a Poisson model for a range of lambda, using the observed number of patents as the input data. The curve peaks at the value of 3 that best fits the data, which is the maximum likelihood estimate (MLE).\nWe can also look at it in mathematical view:\nThe log-likelihood function for \\(Y = \\{y_1, y_2, \\dots, y_n\\}\\) is:\n\\[\n\\log L(\\lambda; Y) = \\sum_{i=1}^n \\left( -\\lambda + y_i \\log \\lambda - \\log(y_i!) \\right)\n\\]\nTaking the derivative with respect to \\(\\lambda\\):\n\\[\n\\frac{d}{d\\lambda} \\log L(\\lambda; Y) = \\sum_{i=1}^n \\left( -1 + \\frac{y_i}{\\lambda} \\right)\n= -n + \\frac{1}{\\lambda} \\sum_{i=1}^n y_i\n\\]\nSet the derivative equal to zero:\n\\[\n-n + \\frac{1}{\\lambda} \\sum_{i=1}^n y_i = 0\n\\]\nSolving for \\(\\lambda\\):\n\\[\n\\lambda_{\\text{MLE}} = \\frac{1}{n} \\sum_{i=1}^n y_i = \\bar{Y}\n\\]\nThis result feels right, because the mean of a Poisson distribution is \\(\\lambda\\), and we’re estimating it using the sample mean.\nNow we find the MLE by optimizing my likelihood function.\n\nfrom scipy.optimize import minimize_scalar\n\n# Objective function: negative log-likelihood (for minimization)\ndef neg_loglikelihood(lmbda):\n    return -poisson_loglikelihood(lmbda, Y)\n\n# Use bounded scalar optimization\nresult = minimize_scalar(neg_loglikelihood, bounds=(0.01, 10), method='bounded')\n\nlambda_mle = result.x\nprint(f\"MLE of lambda: {lambda_mle:.4f}\")\n\nMLE of lambda: 3.6847\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\nNow we create a new log-likelihood function for Poisson model with an additional argument to take in a covariate matrix X. We will use it to find the MLE vector and the Hessian of the Poisson model with covariates. Then we will use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\n\nfrom scipy.special import gammaln\nfrom scipy.optimize import minimize\nimport math\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    beta = np.asarray(beta).ravel()\n    X = np.asarray(X)\n    Y = np.asarray(Y)\n\n    linpred = X.dot(beta)\n    linpred = np.clip(linpred, -100, 100)\n\n    mu = np.array([math.exp(val) for val in linpred])\n\n    if np.any(mu &lt;= 0) or np.any(np.isnan(mu)):\n        return -np.inf\n\n    return np.sum(Y * np.log(mu) - mu - gammaln(Y + 1))\n\n\ndf['age_squared'] = df['age'] ** 2\nregion_dummies = pd.get_dummies(df['region'], drop_first=True)\nX = pd.concat([\n    pd.Series(1, index=df.index, name='intercept'),\n    df[['age', 'age_squared', 'iscustomer']],\n    region_dummies\n], axis=1)\nY = df['patents'].values\nX_matrix = X.values\n\ndef neg_loglikelihood(beta, Y, X):\n    return -poisson_regression_loglikelihood(beta, Y, X)\n\n# Optimize to find MLE\ninitial_beta = np.zeros(X_matrix.shape[1])\nresult = minimize(neg_loglikelihood, x0=initial_beta, args=(Y, X_matrix), method='BFGS')\n\n# Extract MLE and Hessian inverse\nbeta_mle = result.x\nhess_inv = result.hess_inv\n# Ensure Hessian inverse is array\nif not isinstance(hess_inv, np.ndarray):\n    hess_inv = hess_inv.todense()\nhess_inv = np.asarray(hess_inv)\n\n# Compute standard errors\nstd_errors = np.sqrt(np.diag(hess_inv))\n\n# Build results table\nresults_df = pd.DataFrame({\n    \"Coefficient\": beta_mle,\n    \"Std. Error\": std_errors\n}, index=X.columns)\nresults_df\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.509992\n0.000099\n\n\nage\n0.148706\n0.003625\n\n\nage_squared\n-0.002972\n0.000095\n\n\niscustomer\n0.207609\n0.028353\n\n\nNortheast\n0.029155\n0.042425\n\n\nNorthwest\n-0.017578\n0.053198\n\n\nSouth\n0.056565\n0.051524\n\n\nSouthwest\n0.050567\n0.046869\n\n\n\n\n\n\n\nNow we check our results using Python sm.GLM() function.\n\nimport statsmodels.api as sm\n\nX_numeric = X.astype(float)\nY_numeric = Y.astype(float)\n\npoisson_model = sm.GLM(Y_numeric, X_numeric, family=sm.families.Poisson())\npoisson_results = poisson_model.fit()\nprint(poisson_results.summary())\n\n# And to extract coeffs and SEs:\nimport pandas as pd\nresult_table = pd.DataFrame({\n    'coef': poisson_results.params,\n    'std_err': poisson_results.bse\n})\nprint(result_table)\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Wed, 07 May 2025   Deviance:                       2143.3\nTime:                        23:17:34   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n-------------------------------------------------------------------------------\nintercept      -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nage             0.1486      0.014     10.716      0.000       0.121       0.176\nage_squared    -0.0030      0.000    -11.513      0.000      -0.003      -0.002\niscustomer      0.2076      0.031      6.719      0.000       0.147       0.268\nNortheast       0.0292      0.044      0.669      0.504      -0.056       0.115\nNorthwest      -0.0176      0.054     -0.327      0.744      -0.123       0.088\nSouth           0.0566      0.053      1.074      0.283      -0.047       0.160\nSouthwest       0.0506      0.047      1.072      0.284      -0.042       0.143\n===============================================================================\n                 coef   std_err\nintercept   -0.508920  0.183179\nage          0.148619  0.013869\nage_squared -0.002970  0.000258\niscustomer   0.207591  0.030895\nNortheast    0.029170  0.043625\nNorthwest   -0.017575  0.053781\nSouth        0.056561  0.052662\nSouthwest    0.050576  0.047198\n\n\nFrom the result above, we can see age has a strong nonlinear relationship with patent counts: the negative age squared term and the positive age term shows that age increases the expected log count until 25, and then make it decline afterwards. Blueprinty customers produce about 23 percent more patents than non-customers (exp(0.208)≈1.23, p &lt; .001), given all other conditions equal. Once age and customer status are accounted for, none of the regions—Northeast, Northwest, South, or Southwest—differs significantly from the Midwest baseline.\nNow we want to conclude on the effect of Blueprinty’s software on patent success. Because the beta coefficients are not directly interpretable, we create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, we use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences._\n\ndef build_design_matrix(df, iscustomer=None, region_dummies=None):\n    X = pd.DataFrame({\n        'intercept': 1.0,\n        'age': df['age'].astype(float),\n        'age_squared': df['age_squared'].astype(float),\n    }, index=df.index)\n    \n    if region_dummies is not None:\n        region_dummies = region_dummies.astype(float)\n        X = pd.concat([X, region_dummies], axis=1)\n\n    if iscustomer is None:\n        X['iscustomer'] = df['iscustomer'].astype(float)\n    else:\n        X['iscustomer'] = float(iscustomer)\n        \n    cols_order = ['intercept', 'age', 'age_squared', 'iscustomer'] + list(region_dummies.columns)\n    return X[cols_order]\n\nX_full = build_design_matrix(df, region_dummies=region_dummies)\nX_0 = build_design_matrix(df, iscustomer=0, region_dummies=region_dummies)\nX_1 = build_design_matrix(df, iscustomer=1, region_dummies=region_dummies)\n\nY = df['patents'].astype(float)\n\npoisson_model = sm.GLM(Y, X_full, family=sm.families.Poisson())\npoisson_result = poisson_model.fit()\n\ny_pred_0 = poisson_result.predict(X_0)\ny_pred_1 = poisson_result.predict(X_1)\n\naverage_effect = np.mean(y_pred_1 - y_pred_0)\naverage_effect\n\n0.7927680710452626\n\n\nWe can see that, on average, Blueprinty customers are expected to produce approximately 0.79 more patents than if they were not customers, holding all other variables constant."
  },
  {
    "objectID": "blog/HW2/index.html#airbnb-case-study",
    "href": "blog/HW2/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\ndf = pd.read_csv(\"airbnb.csv\")\ndf.describe(include='all')\n\n\n\n\n\n\n\n\nUnnamed: 0\nid\ndays\nlast_scraped\nhost_since\nroom_type\nbathrooms\nbedrooms\nprice\nnumber_of_reviews\nreview_scores_cleanliness\nreview_scores_location\nreview_scores_value\ninstant_bookable\n\n\n\n\ncount\n40628.000000\n4.062800e+04\n40628.000000\n40628\n40593\n40628\n40468.000000\n40552.000000\n40628.000000\n40628.000000\n30433.000000\n30374.000000\n30372.000000\n40628\n\n\nunique\nNaN\nNaN\nNaN\n2\n2790\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2\n\n\ntop\nNaN\nNaN\nNaN\n4/2/2017\n12/21/2015\nEntire home/apt\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nf\n\n\nfreq\nNaN\nNaN\nNaN\n25737\n65\n19873\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n32759\n\n\nmean\n20314.500000\n9.698889e+06\n1102.368219\nNaN\nNaN\nNaN\n1.124592\n1.147046\n144.760732\n15.904426\n9.198370\n9.413544\n9.331522\nNaN\n\n\nstd\n11728.437705\n5.460166e+06\n1383.269358\nNaN\nNaN\nNaN\n0.385884\n0.691746\n210.657597\n29.246009\n1.119935\n0.844949\n0.902966\nNaN\n\n\nmin\n1.000000\n2.515000e+03\n1.000000\nNaN\nNaN\nNaN\n0.000000\n0.000000\n10.000000\n0.000000\n2.000000\n2.000000\n2.000000\nNaN\n\n\n25%\n10157.750000\n4.889868e+06\n542.000000\nNaN\nNaN\nNaN\n1.000000\n1.000000\n70.000000\n1.000000\n9.000000\n9.000000\n9.000000\nNaN\n\n\n50%\n20314.500000\n9.862878e+06\n996.000000\nNaN\nNaN\nNaN\n1.000000\n1.000000\n100.000000\n4.000000\n10.000000\n10.000000\n10.000000\nNaN\n\n\n75%\n30471.250000\n1.466789e+07\n1535.000000\nNaN\nNaN\nNaN\n1.000000\n1.000000\n170.000000\n17.000000\n10.000000\n10.000000\n10.000000\nNaN\n\n\nmax\n40628.000000\n1.800967e+07\n42828.000000\nNaN\nNaN\nNaN\n8.000000\n10.000000\n10000.000000\n421.000000\n10.000000\n10.000000\n10.000000\nNaN\n\n\n\n\n\n\n\n\ndf.isna().sum()\n\nUnnamed: 0                       0\nid                               0\ndays                             0\nlast_scraped                     0\nhost_since                      35\nroom_type                        0\nbathrooms                      160\nbedrooms                        76\nprice                            0\nnumber_of_reviews                0\nreview_scores_cleanliness    10195\nreview_scores_location       10254\nreview_scores_value          10256\ninstant_bookable                 0\ndtype: int64\n\n\n\n# EDA\nplt.figure(); plt.hist(df['number_of_reviews'], bins=50); plt.title('Distribution of Number of Reviews'); plt.xlabel('Number of Reviews'); plt.ylabel('Frequency'); plt.show()\nplt.figure(); plt.scatter(df['price'], df['number_of_reviews'], alpha=0.3); plt.title('Price vs Number of Reviews'); plt.xlabel('Price'); plt.ylabel('Number of Reviews'); plt.xlim(0, 1000); plt.show()\nplt.figure(); plt.scatter(df['days'], df['number_of_reviews'], alpha=0.3); plt.title('Days Listed vs Number of Reviews'); plt.xlabel('Days Listed'); plt.ylabel('Number of Reviews'); plt.show()\nplt.figure(); sns.boxplot(x='room_type', y='number_of_reviews', data=df); plt.title('Room Type vs Number of Reviews'); plt.xlabel('Room Type'); plt.ylabel('Number of Reviews'); plt.show()\nprint(df[['number_of_reviews','days','bathrooms','bedrooms','price']].corr())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                   number_of_reviews      days  bathrooms  bedrooms     price\nnumber_of_reviews           1.000000  0.103633  -0.015352  0.024425 -0.014181\ndays                        0.103633  1.000000  -0.012517  0.006445  0.015026\nbathrooms                  -0.015352 -0.012517   1.000000  0.408714  0.252303\nbedrooms                    0.024425  0.006445   0.408714  1.000000  0.275643\nprice                      -0.014181  0.015026   0.252303  0.275643  1.000000\n\n\n\nimport statsmodels.formula.api as smf\n# Poisson regression\npoisson_model = smf.glm(\n    'number_of_reviews ~ days + price + bathrooms + bedrooms + C(room_type) + instant_bookable',\n    data=df, family=sm.families.Poisson()\n).fit()\nprint(poisson_model.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:      number_of_reviews   No. Observations:                40395\nModel:                            GLM   Df Residuals:                    40387\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:            -7.0857e+05\nDate:                Wed, 07 May 2025   Deviance:                   1.2940e+06\nTime:                        23:17:35   Pearson chi2:                 2.08e+06\nNo. Iterations:                    11   Pseudo R-squ. (CS):             0.5681\nCovariance Type:            nonrobust                                         \n================================================================================================\n                                   coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------------------------\nIntercept                        2.7715      0.004    622.520      0.000       2.763       2.780\nC(room_type)[T.Private room]    -0.1531      0.003    -53.692      0.000      -0.159      -0.147\nC(room_type)[T.Shared room]     -0.4080      0.009    -47.120      0.000      -0.425      -0.391\ninstant_bookable[T.t]            0.3748      0.003    130.046      0.000       0.369       0.380\ndays                          5.022e-05   3.57e-07    140.825      0.000    4.95e-05    5.09e-05\nprice                           -0.0005   1.23e-05    -37.560      0.000      -0.000      -0.000\nbathrooms                       -0.1064      0.004    -27.723      0.000      -0.114      -0.099\nbedrooms                         0.0982      0.002     48.981      0.000       0.094       0.102\n================================================================================================\n\n\nHere we run a Poisson regression and to describe variation in the number of reviews as a function of the variables provided:\n\nBaseline (Intercept)\n\n\nIntercept = 2.7715\n\nexp(2.7715) = 16.0 – Expected number of reviews for the reference listing (entire home/apt, non-instant-bookable, 0 days listed, $0 price, 0 bedrooms, 0 bathrooms).\n\n\nDays listed (days)\n\n\ncoef = +0.00005022\nexp(0.00005022) = 1.0000502 – +0.005% expected reviews per extra day listed.\n– Over 100 days: 1.0000502^{100} → 0.5% increase.\n\n\nPrice (price)\n\n\ncoef = -0.0005\n\nexp(-0.0005) = 0.9995 – –0.05% expected reviews per $1 increase.\n– For $100 more: (-0.0005) → 4.9% decrease.\n\n\nBathrooms (bathrooms)\n\n\nbeta = -0.1064\nexp(-0.1064) = 0.899 – 10.1% fewer expected reviews per additional bathroom.\n\n\nBedrooms (bedrooms)\n\n\nbeta = +0.0982\nexp(0.0982)= 1.103 – 10.3% more expected reviews per additional bedroom.\n\n\nRoom type (room_type, reference = Entire home/apt)\n\n\nPrivate room: coef = -0.1531 → exp(-0.1531) = 0.858 ⇒ 14.2% fewer reviews\n\nShared room: coef = -0.4080 → exp(-0.4080) = 0.665 ⇒ 33.5% fewer reviews\n\n\nInstant bookable (instant_bookable)\n\n\ncoef = +0.3748\n\nexp(0.3748) = 1.454\n– 45.4% more expected reviews if instant-bookable."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "blog/HW1/index.html",
    "href": "blog/HW1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment aimed to evaluate how different fundraising strategies influence donor behavior. The standard letter served as a baseline, while the matching grant letter offered to match donations at a specific ratio, and the challenge grant letter set a fundraising goal that needed to be met for the funds to be unlocked. These treatments were designed to test the psychological and economic factors that motivate charitable giving, such as reciprocity, social pressure, and perceived impact.\nThe study measured key outcomes, including the likelihood of donating and the amount donated, to assess the effectiveness of each treatment. By randomly assigning participants to treatment groups, the researchers ensured that any observed differences in outcomes could be attributed to the fundraising strategy rather than external factors. This rigorous design allowed them to draw causal inferences about the impact of the treatments on donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/HW1/index.html#introduction",
    "href": "blog/HW1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment aimed to evaluate how different fundraising strategies influence donor behavior. The standard letter served as a baseline, while the matching grant letter offered to match donations at a specific ratio, and the challenge grant letter set a fundraising goal that needed to be met for the funds to be unlocked. These treatments were designed to test the psychological and economic factors that motivate charitable giving, such as reciprocity, social pressure, and perceived impact.\nThe study measured key outcomes, including the likelihood of donating and the amount donated, to assess the effectiveness of each treatment. By randomly assigning participants to treatment groups, the researchers ensured that any observed differences in outcomes could be attributed to the fundraising strategy rather than external factors. This rigorous design allowed them to draw causal inferences about the impact of the treatments on donor behavior.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/HW1/index.html#data",
    "href": "blog/HW1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Display basic information about the dataset\nprint(\"Dataset Overview:\")\nprint(df.info())\n\n# Summary statistics\nprint(\"\\nSummary Statistics:\")\nprint(df.describe())\n\nDataset Overview:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\nNone\n\nSummary Statistics:\n          treatment       control        ratio2        ratio3        size25  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.666813      0.333187      0.222311      0.222211      0.166723   \nstd        0.471357      0.471357      0.415803      0.415736      0.372732   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n75%        1.000000      1.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n             size50       size100        sizeno         askd1         askd2  \\\ncount  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \nmean       0.166623      0.166723      0.166743      0.222311      0.222291   \nstd        0.372643      0.372732      0.372750      0.415803      0.415790   \nmin        0.000000      0.000000      0.000000      0.000000      0.000000   \n25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n75%        0.000000      0.000000      0.000000      0.000000      0.000000   \nmax        1.000000      1.000000      1.000000      1.000000      1.000000   \n\n       ...        redcty       bluecty        pwhite        pblack  \\\ncount  ...  49978.000000  49978.000000  48217.000000  48047.000000   \nmean   ...      0.510245      0.488715      0.819599      0.086710   \nstd    ...      0.499900      0.499878      0.168561      0.135868   \nmin    ...      0.000000      0.000000      0.009418      0.000000   \n25%    ...      0.000000      0.000000      0.755845      0.014729   \n50%    ...      1.000000      0.000000      0.872797      0.036554   \n75%    ...      1.000000      1.000000      0.938827      0.090882   \nmax    ...      1.000000      1.000000      1.000000      0.989622   \n\n          page18_39     ave_hh_sz  median_hhincome        powner  \\\ncount  48217.000000  48221.000000     48209.000000  48214.000000   \nmean       0.321694      2.429012     54815.700533      0.669418   \nstd        0.103039      0.378115     22027.316665      0.193405   \nmin        0.000000      0.000000      5000.000000      0.000000   \n25%        0.258311      2.210000     39181.000000      0.560222   \n50%        0.305534      2.440000     50673.000000      0.712296   \n75%        0.369132      2.660000     66005.000000      0.816798   \nmax        0.997544      5.270000    200001.000000      1.000000   \n\n       psch_atlstba  pop_propurban  \ncount  48215.000000   48217.000000  \nmean       0.391661       0.871968  \nstd        0.186599       0.258654  \nmin        0.000000       0.000000  \n25%        0.235647       0.884929  \n50%        0.373744       1.000000  \n75%        0.530036       1.000000  \nmax        1.000000       1.000000  \n\n[8 rows x 48 columns]\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport statsmodels.api as sm\n\nvariables_to_test = ['mrm2', 'freq', 'years']\n\nfor var in variables_to_test:\n    print(f\"\\n=== Testing variable: {var} ===\")\n    group_means = df.groupby('treatment')[var].mean()\n    group_counts = df.groupby('treatment')[var].count()\n    group_vars = df.groupby('treatment')[var].var()\n    n1 = group_counts[1]  \n    n0 = group_counts[0] \n    mean1 = group_means[1]\n    mean0 = group_means[0]\n    var1 = group_vars[1]\n    var0 = group_vars[0]\n    \n    print(f\"Treatment mean: {mean1:.3f}, Control mean:{mean0:.3f}\")\n    print(f\"Treatment std: {var1**0.5:.3f}, Control variance:{var0**0.5:.3f}\")\n\n    se = np.sqrt(var1/n1 + var0/n0)\n    t_stat = (mean1 - mean0) / se\n    dfree = (var1/n1 + var0/n0)**2 / ((var1**2)/((n1**2)*(n1-1)) + (var0**2)/((n0**2)*(n0-1)))\n    p_value = 2 * (1 - stats.t.cdf(np.abs(t_stat), df=dfree))\n    print(f\"T-test: t = {t_stat:.3f}, p = {p_value:.3f}\")\n\n    X = sm.add_constant(df['treatment'])\n    y = df[var]\n    model = sm.OLS(y, X, missing='drop').fit()\n    coef = model.params['treatment']\n    pval = model.pvalues['treatment']\n    print(f\"Regression: coef = {coef:.3f}, p = {pval:.3f}\")\n\n\n=== Testing variable: mrm2 ===\nTreatment mean: 13.012, Control mean:12.998\nTreatment std: 12.086, Control variance:12.074\nT-test: t = 0.120, p = 0.905\nRegression: coef = 0.014, p = 0.905\n\n=== Testing variable: freq ===\nTreatment mean: 8.035, Control mean:8.047\nTreatment std: 11.390, Control variance:11.404\nT-test: t = -0.111, p = 0.912\nRegression: coef = -0.012, p = 0.912\n\n=== Testing variable: years ===\nTreatment mean: 6.078, Control mean:6.136\nTreatment std: 5.442, Control variance:5.625\nT-test: t = -1.091, p = 0.275\nRegression: coef = -0.058, p = 0.270\n\n\nThe t-test and linear regression both test for mean differences between the treatment and control groups on these baseline variables, and the results should be identical. This result is also aligned with the Table 1 in the paper. ## Experimental Results\n\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates by group\ndonation_rates = df.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\n\nplt.bar(labels, donation_rates)\nplt.ylabel('Proportion Donated')\nplt.title('Proportion of People Who Donated by Group')\nplt.ylim(0, donation_rates.max() * 1.2)\nplt.show()\n\n\n\n\n\n\n\n\nAbove is the proportion of people who donated in control and treatment groups.\nNext, I run a t-test and a bivariate linear regression between the treatment and control groups on the binary outcome of whether any charitable donation was made.\n\nimport numpy as np\nimport statsmodels.api as sm\nfrom scipy import stats\n\ndf_clean = df[['gave', 'treatment']].dropna()\n\ngave_treatment = df_clean[df_clean['treatment'] == 1]['gave']\ngave_control = df_clean[df_clean['treatment'] == 0]['gave']\n\nt_stat, p_value = stats.ttest_ind(\n    gave_treatment,\n    gave_control,\n    equal_var=False\n)\nprint(f\"T-test (scipy): t = {t_stat:.3f}, p = {p_value:.4f}\")\n\n# Linear regression\nX = sm.add_constant(df_clean['treatment'])\ny = df_clean['gave']\nmodel = sm.OLS(y, X).fit()\ncoef = model.params['treatment']\npval = model.pvalues['treatment']\nprint(f\"Regression: coef = {coef:.3f}, p = {pval:.4f}\")\n\nT-test (scipy): t = 3.209, p = 0.0013\nRegression: coef = 0.004, p = 0.0019\n\n\nBoth the t-test and regression show whether the treatment group is more likely to donate than the control group.\nThe p-value is small(&lt;0.01), which means the difference is statistically significant: the matching grant treatment increases the likelihood of giving. This suggests that people are more likely to donate when their gift is matched, supporting the idea that matching grants motivate charitable behavior.\nThen, I ran a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control.\n\ndf_clean = df[['gave', 'treatment']].dropna()\n\nX = sm.add_constant(df_clean['treatment'])\ny = df_clean['gave']\n\nprobit_model = sm.Probit(y, X).fit()\n\nmarginal_effects = probit_model.get_margeff(at='overall')\nprint(marginal_effects.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nThe coefficient on ‘treatment’ should match Table 3 column 1 in the paper. A positive and significant coefficient here means being assigned to the treatment group increases the probability of making a donation, consistent with the main findings.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nFirst, I used a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not between every two sizes (1:1 vs 2:1, 2:1 vs 3:1, 1:1 vs 3:1).\n\ndf_ratio = df[(df['treatment'] == 1) & (df['ratio'].notnull()) & (df['gave'].notnull())]\n\n# 1:1 vs 2:1\ngave_1to1 = df_ratio[df_ratio['ratio'] == 1]['gave']\ngave_2to1 = df_ratio[df_ratio['ratio'] == 2]['gave']\nt_stat_12, p_val_12 = stats.ttest_ind(gave_1to1, gave_2to1, equal_var=False)\nprint(f\"1:1 vs 2:1 match: t = {t_stat_12:.3f}, p = {p_val_12:.4f}\")\n\n# 2:1 vs 3:1\ngave_3to1 = df_ratio[df_ratio['ratio'] == 3]['gave']\nt_stat_23, p_val_23 = stats.ttest_ind(gave_2to1, gave_3to1, equal_var=False)\nprint(f\"2:1 vs 3:1 match: t = {t_stat_23:.3f}, p = {p_val_23:.4f}\")\n\n# 1:1 vs 3:1\nt_stat_13, p_val_13 = stats.ttest_ind(gave_1to1, gave_3to1, equal_var=False)\nprint(f\"1:1 vs 3:1 match: t = {t_stat_13:.3f}, p = {p_val_13:.4f}\")\n\n1:1 vs 2:1 match: t = -0.965, p = 0.3345\n2:1 vs 3:1 match: t = -0.050, p = 0.9600\n1:1 vs 3:1 match: t = -1.015, p = 0.3101\n\n\nThese t-tests shows that there is no statistically significant difference in donation rates between the match ratios.\nThis supports the authors’ comment that “neither the match thresh- old nor the example amount had a meaningful influence on behavior.”\nNext, I assessed the same issue using a regression. I created the variable ratio2, and ratio3, and then regressed gave on them.\n\ndf_ratio = df[(df['treatment'] == 1) & (df['ratio'].isin([1,2,3])) & (df['gave'].notnull())]\n\ndf_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\nX = sm.add_constant(df_ratio[['ratio2', 'ratio3']])\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Wed, 07 May 2025   Prob (F-statistic):              0.524\nTime:                        23:17:38   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n/var/folders/4l/zkt81q5j4xlbn6fjv2v8jj880000gn/T/ipykernel_87262/1592154894.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\n/var/folders/4l/zkt81q5j4xlbn6fjv2v8jj880000gn/T/ipykernel_87262/1592154894.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\n\n\nThe coefficients on the dummy variables for match ratios show the difference in donation probability compared to the 1:1 match (the omitted group). The coefficients are small and not statistically significant, which means increasing the match ratio does not meaningfully affect the likelihood of donating.\nThis matches the earlier t-test results and supports the paper’s finding.\nI also calculated the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios in two ways – directly from the data, and by computing the differences in the fitted coefficients of the previous regression.\n\ngave_1to1 = df_ratio[df_ratio['ratio'] == 1]['gave']\ngave_2to1 = df_ratio[df_ratio['ratio'] == 2]['gave']\ngave_3to1 = df_ratio[df_ratio['ratio'] == 3]['gave']\n\ndiff_12 = gave_2to1.mean() - gave_1to1.mean()\ndiff_13 = gave_3to1.mean() - gave_1to1.mean()\ndiff_23 = gave_3to1.mean() - gave_2to1.mean()\nprint(f\"Direct from data: Response rate difference (2:1 - 1:1): {diff_12:.4f}\")\nprint(f\"Direct from data: Response rate difference (3:1 - 1:1): {diff_13:.4f}\")\nprint(f\"Direct from data: Response rate difference (3:1 - 2:1): {diff_23:.4f}\")\n\n\ncoef_2 = model.params['ratio2']\ncoef_3 = model.params['ratio3']\nprint(f\"From regression: Response rate difference (2:1 - 1:1): {coef_2:.4f}\")\nprint(f\"From regression: Response rate difference (3:1 - 1:1): {coef_3:.4f}\")\nprint(f\"From regression: Response rate difference (3:1 - 2:1): {(coef_3 - coef_2):.4f}\")\n\nDirect from data: Response rate difference (2:1 - 1:1): 0.0019\nDirect from data: Response rate difference (3:1 - 1:1): 0.0020\nDirect from data: Response rate difference (3:1 - 2:1): 0.0001\nFrom regression: Response rate difference (2:1 - 1:1): 0.0019\nFrom regression: Response rate difference (3:1 - 1:1): 0.0020\nFrom regression: Response rate difference (3:1 - 2:1): 0.0001\n\n\nBoth the direct calculation and regression coefficients show that the differences in response rates between 1:1, 2:1, and 3:1 match ratios are very small and not statistically significant. This suggests that increasing the match ratio does not meaningfully increase the likelihood of donating, confirming the findings in the paper.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nI first examined whether the treatment group gives a different average donation amount than the control group by t-test.\n\ndf_amt = df[['amount', 'treatment']].dropna()\n\namount_treat = df_amt[df_amt['treatment'] == 1]['amount']\namount_ctrl = df_amt[df_amt['treatment'] == 0]['amount']\nt_stat, p_value = stats.ttest_ind(amount_treat, amount_ctrl, equal_var=False)\nprint(f\"T-test: t = {t_stat:.3f}, p = {p_value:.4f}\")\n\nT-test: t = 1.918, p = 0.0551\n\n\nThe p-value is large (&gt;0.05), it means there is no statistically significant difference in average donation amount between groups. This suggests that while matching grants may increase the likelihood of giving, they do not necessarily increase the average amount donated.\nThen, I limited the data to just people who made a donation and repeat the previous analysis. This regression allows me to analyze how much respondents donate conditional on donating some positive amount.\n\ndf_positive = df[(df['gave'] == 1) & (df['treatment'].notnull())].copy()\n\nX = sm.add_constant(df_positive['treatment'])\ny = df_positive['amount']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 07 May 2025   Prob (F-statistic):              0.561\nTime:                        23:17:39   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThis analysis examines whether, among those who donated, the average donation amount differs between treatment and control groups.\nThe treatment coefficient is not statistically significant, which suggests that matching grants do not increase the average donation size among donors—only the likelihood of giving. Because treatment was randomly assigned, the coefficient can be interpreted causally: it estimates the effect of being offered a match on the average donation amount, conditional on donating.\nHere I make two plots to show the distribution of the donation amounts for people who donated in treatment and control groups. This also support the conclusion that matching grants do not increase the average donation size among donors—only the likelihood of giving.\n\ndf_positive = df[(df['amount'] &gt; 0) & (df['treatment'].notnull())]\n\namount_treat = df_positive[df_positive['treatment'] == 1]['amount']\nmean_treat = amount_treat.mean()\n\namount_ctrl = df_positive[df_positive['treatment'] == 0]['amount']\nmean_ctrl = amount_ctrl.mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control histogram\naxes[0].hist(amount_ctrl, bins=30, color='gray', alpha=0.7)\naxes[0].axvline(mean_ctrl, color='red', linestyle='dashed', linewidth=2, label=f'Mean = {mean_ctrl:.2f}')\naxes[0].set_title('Control Group')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Number of Donors')\naxes[0].legend()\n\n# Treatment histogram\naxes[1].hist(amount_treat, bins=30, color='skyblue', alpha=0.7)\naxes[1].axvline(mean_treat, color='red', linestyle='dashed', linewidth=2, label=f'Mean = {mean_treat:.2f}')\naxes[1].set_title('Treatment Group')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/HW1/index.html#simulation-experiment",
    "href": "blog/HW1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nTo illustrate Law of Large Numbers, I simulated 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. I then calculated a vector of 10,000 differences, and then plot the cumulative average of that vector of differences.\n\nnp.random.seed(42)\n\n\ncontrol_draws = np.random.binomial(1, 0.018, 10000)\ntreatment_draws = np.random.binomial(1, 0.022, 10000)\n\n# Calculate vector of differences\ndiffs = treatment_draws - control_draws\n\n# Cumulative average of differences\ncum_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# True difference in means\ntrue_diff = 0.022 - 0.018\n\nplt.figure(figsize=(10, 5))\nplt.plot(cum_avg, label='Cumulative Average of Differences')\nplt.axhline(true_diff, color='red', linestyle='--', label='True Difference in Means')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.title('Cumulative Average of Simulated Differences (Treatment - Control)')\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis plot shows how the cumulative average of the simulated differences between treatment and control groups converges to the true difference in means as the number of simulations increases.\nAs more samples are drawn, the cumulative average stabilizes around the true value (0.004), illustrating the Law of Large Numbers.\n\n\nCentral Limit Theorem\nTo illustrate Central Limit Theorem, I made 4 histograms at sample sizes 50, 200, 500, and 1000. For each sample size, e.g. 50, I took 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that I had 1000 averages.\n\nnp.random.seed(42)\n\np_control = 0.018\np_treatment = 0.022\nsample_sizes = [50, 200, 500, 1000]\nn_reps = 1000\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    avg_diffs = []\n    for _ in range(n_reps):\n        control_draws = np.random.binomial(1, p_control, n)\n        treatment_draws = np.random.binomial(1, p_treatment, n)\n        avg_diff = treatment_draws.mean() - control_draws.mean()\n        avg_diffs.append(avg_diff)\n    axes[i].hist(avg_diffs, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n    axes[i].axvline(0, color='red', linestyle='dashed', linewidth=2, label='Zero')\n    axes[i].axvline(p_treatment - p_control, color='green', linestyle='dashed', linewidth=2, label='True Diff')\n    axes[i].set_title(f'Sample Size = {n}')\n    axes[i].set_xlabel('Average Difference')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nEach histogram shows the distribution of average differences in donation rates between treatment and control groups, simulated 1000 times for different sample sizes.\nAs the sample size increases, the distribution becomes narrower and more centered around the true difference (green line), and zero (red line) moves further into the tail.\nThis illustrates the Central Limit Theorem: with larger samples, our estimate of the difference becomes more precise and less likely to include zero if there is a true effect."
  }
]